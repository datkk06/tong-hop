# Cài đặt đẩy log về ELK sử dụng cache (kafka).

## 1. Giới thiệu về Kafka.

- Kafka là hệ thống message pub/sub phân tán mà có khả năng scale rất tốt.

- Message của kafka được lưu trên đĩa cứng, đồng thời được replicate trong cluster giúp phòng tránh mất dữ liệu.

- Kafka có thể hiểu là một hệ thống logging, nhằm lưu lại các trạng thái của hệ thống, nhằm phòng tránh mất thông tin.

- Các khái niệm cơ bản :

    - Kafka lưu, phân loại message theo topics.

    - Kafka sử dụng producers để publish message vào các topics ở trên.

    - Kafka sử dụng consumers để subscribe vào topics, sau đó xử lý các message lấy được theo một logic nào đó.

    - Kafka thường được chạy dưới dạng cluster, khi đó mỗi server trong đó sẽ được gọi là broker.

![kafka-1](/images/kafka-1.png)

### 1.1. Topic.

- Topic có thể hiểu là một ngôn ngữ chung giữa producer (người nói) và consumer (người nghe, sử dụng).
Với mỗi topic, kafka sẽ duy trì thông qua partitioned log như dưới đây:

![kafka-2](/images/kafka-2.png)

- Mỗi partition là một chuỗi log, có thứ tự và không thể thay đổi (immutable).

- Mỗi message trong partition sẽ có id tăng dần , gọi là offset.

- Kafka cluster sẽ lưu lại mọi message đã được published, cho dù message đó đã được/chưa được sử dụng (consume). Thời gian lưu message có thể tuỳ chỉnh được thông qua log retention.

- Consumer sẽ điều khiển những gì mình muốn đọc thông qua offset của message, hay thậm chí là thứ tự đọc. Consumer có thể reset lại vị trí của offset để re-process lại một vài message nào đó.

### 1.2. Producer.

- Như đã nói ở trên, producer nhằm mục đích chính là ném message vào topic. Cụ thể hơn là producer có nhiệm vụ là chọn message nào, để ném vào partition nào trong topic. Nhiệm vụ này rất quan trọng, giúp cho kafka có khả năng "scale" tốt.

![kafka-3](/images/kafka-3.png)

### 1.3. Consumer.

- Thông thường thì một hệ thống messaging sẽ có 2 loại :

    - Queue: Một message sẽ được xử lý bời một consumer.

    - Pub/Sub: Một message sẽ được xử lý bởi một vài consumer thích hợp, tuỳ theo topic.

- Ở kafka chúng ta có một khái niệm gọi là consumer group giúp chúng ta có thể làm được đồng thời cả 2 loại trên, rất thú vị. Việc subscribe một topic sẽ được thực hiện bởi consumer group. Mỗi một message sẽ được gửi cho `duy nhất` một consumer instance trong một consumer group. Việc này dấn đến :

    - Nếu nhiều instance consumer có cùng group: chúng ta sẽ có một hệ thống queue.

    - Nếu mỗi instance là một group, chúng ta sẽ có một hệ thống pub/sub.

### 1.4. Use cases.

- Sử dụng như một hệ thống message queue thay thế cho ActiveMQ hay RabbitMQ.

- Tracking hành động người dùng : các thông số như page view, search action của user sẽ được publish vào một topic và sẽ được xử lý sau.

- Log Aggregration: log sẽ được gửi từ nhiều server về một nơi thống nhất, sau đó có thể được làm sạch và xử lý theo một logic nào đó.

- Event-Sourcing: Lưu lại trạng thái của hệ thống để có thể tái hiện trong trường hợp system bị down. 



## Install Kafka Centos 7

 - Dowload kafka
 
  ```sh
  wget http://mirror.downloadvn.com/apache/kafka/1.1.0/kafka_2.11-1.1.0.tgz
  ```

 - Giải nén kafka

  ```sh 
  tar -zxvf kafka_2.11-1.1.0.tgz
  ```

##Install java8

  ```sh
  yum install java-1.8.0-openjdk -y
  ```

#Echo enviroment

```sh
echo "export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk" >> /etc/environment
echo "export JRE_HOME=/usr/lib/jvm/jre" >> /etc/environment
```

#Firewall

```sh
firewall-cmd --add-port=9092/tcp
firewall-cmd --add-port=9092/tcp --permanent
```

##Config file :

  ```sh
  cd kafka_2.11-1.1.0
  vi config/server.properties
  # sửa nội dung phía dưới
  listeners=PLAINTEXT://ip-kafka:9092
  ```

## Chạy file run

  ```sh
  yum install -y screen
  screen -d -m bin/zookeeper-server-start.sh config/zookeeper.properties
  screen -d -m bin/kafka-server-start.sh config/server.properties
  ```

## tạo topic mới để nhận log :

  ```sh
  bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic log-system
  ```

## Kiểm tra trạng thái cluster

```sh
ps aux | grep zookeeper.properties
ps aux | grep server.properties
```

## List topic

```sh
bin/kafka-topics.sh --list --zookeeper localhost:2181
```

## Theo dõi message có trong topic

```sh
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic log-system
```



===================================================

# Cài đặt ELK trên CentOS 7 nhận log từ kafka.


- Cài đặt java :

    ```sh
    yum install java-1.8.0-openjdk -y
    ```

## 1. Cài đặt Elasticsearch.

- Thêm repo :

    ```sh
    rpm --import http://packages.elastic.co/GPG-KEY-elasticsearch
    ```

- Thêm file repo :

    ```sh
    cat <<EOF > /etc/yum.repos.d/elasticsearch.repo
    [elasticsearch-6.x]
    name=Elasticsearch repository for 6.x packages
    baseurl=https://artifacts.elastic.co/packages/6.x/yum
    gpgcheck=1
    gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
    enabled=1
    autorefresh=1
    type=rpm-md
    EOF
    ```

- Cài đặt Elastic :

    ```sh
    yum install elasticsearch -y
    ```

- Mở file file `/etc/elasticsearch/elasticsearch.yml` :

    ```sh
    vi /etc/elasticsearch/elasticsearch.yml
    ```

- Tìm đến dòng `network.host` và sửa lại như sau :

![network.host](/images/network.host.png)

- Khởi động lại `Elasticsearch` và cho phép khởi động cùng hệ thống :

    ```sh
    systemctl restart elasticsearch
    systemctl enabled elasticsearch
    ```

- Thêm rule firewall :

    ```sh
    firewall-cmd --add-port=9200/tcp
    firewall-cmd --add-port=9200/tcp --permanent
    ```

- Kiểm tra dịch vụ Elasticsearch :

    ```sh
    curl -X GET http://localhost:9200
    ```

- Kết quả thu được như sau :

    ```sh
    [root@ELK-stack ~]# curl -X GET http://localhost:9200
    {
    "name" : "w5M4X9m",
    "cluster_name" : "elasticsearch",
    "cluster_uuid" : "3a8frDXuRUaxZnKi1Y_tFQ",
    "version" : {
        "number" : "6.3.1",
        "build_flavor" : "default",
        "build_type" : "rpm",
        "build_hash" : "eb782d0",
        "build_date" : "2018-06-29T21:59:26.107521Z",
        "build_snapshot" : false,
        "lucene_version" : "7.3.1",
        "minimum_wire_compatibility_version" : "5.6.0",
        "minimum_index_compatibility_version" : "5.0.0"
    },
    "tagline" : "You Know, for Search"
    }

    ```

## 2. Cài đặt Logstash.

- Thêm file repo :

    ```sh
    cat << EOF > /etc/yum.repos.d/logstash.repo
    [logstash-6.x]
    name=Elastic repository for 6.x packages
    baseurl=https://artifacts.elastic.co/packages/6.x/yum
    gpgcheck=1
    gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
    enabled=1
    autorefresh=1
    type=rpm-md
    EOF
    ```

- Cài đặt Logstash :

    ```sh
    yum install logstash -y
    ```

- Start và enable service :

    ```sh
    systemctl daemon-reload
    systemctl start logstash
    systemctl enable logstash
    ```

- Cấu hình firewall cho phép Logstash nhận log từ client (port 5044) :

    ```sh
    firewall-cmd --add-port=5044/tcp
    firewall-cmd --add-port=5044/tcp --permanent
    ```

## 3. Cài đặt Kibana.

- Tạo repo cài đặt Kibana :

    ```sh
    cat <<EOF > /etc/yum.repos.d/kibana.repo
    [kibana-6.x]
    name=Kibana repository for 6.x packages
    baseurl=https://artifacts.elastic.co/packages/6.x/yum
    gpgcheck=1
    gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
    enabled=1
    autorefresh=1
    type=rpm-md
    EOF
    ```

- Cài đặt Kibana :

    ```sh
    yum install kibana -y
    sed -i 's/#server.host: "localhost"/server.host: "0.0.0.0"/'g /etc/kibana/kibana.yml
    ```

- Start và enable Kibana :

    ```sh
    systemctl daemon-reload
    systemctl start kibana
    systemctl enable kibana
    ```

- Cho phép truy cập Kibana web interface (port 5601) :

    ```sh
    firewall-cmd --add-port=5601/tcp
    firewall-cmd --add-port=5601/tcp --permanent
    ```

- Truy cập vào Kibana để kiểm tra :

    ```sh
    http://ip-server:5601
    ```

- Kết quả :

![elk-2](/images/elk-2.PNG)


================================================

# Cấu hình file logstash nhận log từ kafka.

- tạo file cấu hình logstash :

  ```sh
  vi /etc/logstash/conf.d/02-logstash.conf
  ```

- Thêm vào file cấu hình như sau :

  ```sh
  input {
      kafka {
              bootstrap_servers => 'ip-kafka:9092'
              topics => ["log-system"]
              codec => json {}
            }
  }

  output {
      elasticsearch {
        hosts => ["localhost:9200"]
        sniffing => true
        index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
      }
  }

  ```

- Khởi động lại logstash :

  ```sh
  systemctl restart logstash
  ```

====================================

# Cài đặt và cấu hình filebeat trên CentOS để đẩy log.

- Thêm repo elastic :

    ```sh
    cat > /etc/yum.repos.d/elastic.repo << EOF
    [elasticsearch-6.x]
    name=Elasticsearch repository for 6.x packages
    baseurl=https://artifacts.elastic.co/packages/6.x/yum
    gpgcheck=1
    gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
    enabled=1
    autorefresh=1
    type=rpm-md
    EOF
    ```

- Cài đặt filebeat :

    ```sh
    yum install filebeat-6.2.4 -y
    ```

- Coppy file cấu hình :

    ```sh
    cp /etc/filebeat/filebeat.yml /etc/filebeat/filebeat.yml.orig
    rm -rf /etc/filebeat/filebeat.yml
    touch /etc/filebeat/filebeat.yml
    ```

- Thêm vào file cấu hình `/etc/filebeat/filebeat.yml` như sau :

  ```sh
  filebeat:
    prospectors:
      - paths:
          - /var/log/*.log
        encoding: utf-8
        input_type: log
        fields:
          level: debug
        document_type: type
    registry_file: /var/lib/filebeat/registry
  output:
    kafka:
      hosts: ["ip-kafka:9092"]
      topic: log-syslog
  logging:
    to_syslog: false
    to_files: true
    files:
      path: /var/log/filebeat
      name: filebeat
      rotateeverybytes: 1048576000 # = 1GB
      keepfiles: 7
    selectors: ["*"]
    level: info

  ```

- Khởi động filebeat :

  ```sh
  systemctl start filebeat
  ```

==================================

# Một số lỗi khi sử dụng kafka làm cache cho ELK.

## 1. Kafka không đọc log từ filebeat đẩy về.

### Nguyên nhân.

### Cách xử lý.

- Khởi động lại kafka :

  ```sh
  sh bin/kafka-server-start.sh config/server.properties
  ```

- Khởi động lại filebeat :

  ```sh
  systemctl stop filebeat
  rm -rf v/var/lib/filebeat/registry
  systemctl start filebeat
  ```