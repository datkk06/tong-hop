# Cài đặt đẩy log về ELK sử dụng cache (kafka).

## 1. Giới thiệu về Kafka.

- Kafka là hệ thống message pub/sub phân tán mà có khả năng scale rất tốt.

- Message của kafka được lưu trên đĩa cứng, đồng thời được replicate trong cluster giúp phòng tránh mất dữ liệu.

- Kafka có thể hiểu là một hệ thống logging, nhằm lưu lại các trạng thái của hệ thống, nhằm phòng tránh mất thông tin.

- Các khái niệm cơ bản :

    - Kafka lưu, phân loại message theo topics.

    - Kafka sử dụng producers để publish message vào các topics ở trên.

    - Kafka sử dụng consumers để subscribe vào topics, sau đó xử lý các message lấy được theo một logic nào đó.

    - Kafka thường được chạy dưới dạng cluster, khi đó mỗi server trong đó sẽ được gọi là broker.

![kafka-1](/images/kafka-1.png)

### 1.1. Topic.

- Topic có thể hiểu là một ngôn ngữ chung giữa producer (người nói) và consumer (người nghe, sử dụng).
Với mỗi topic, kafka sẽ duy trì thông qua partitioned log như dưới đây:

![kafka-2](/images/kafka-2.png)

- Mỗi partition là một chuỗi log, có thứ tự và không thể thay đổi (immutable).

- Mỗi message trong partition sẽ có id tăng dần , gọi là offset.

- Kafka cluster sẽ lưu lại mọi message đã được published, cho dù message đó đã được/chưa được sử dụng (consume). Thời gian lưu message có thể tuỳ chỉnh được thông qua log retention.

- Consumer sẽ điều khiển những gì mình muốn đọc thông qua offset của message, hay thậm chí là thứ tự đọc. Consumer có thể reset lại vị trí của offset để re-process lại một vài message nào đó.

### 1.2. Producer.

- Như đã nói ở trên, producer nhằm mục đích chính là ném message vào topic. Cụ thể hơn là producer có nhiệm vụ là chọn message nào, để ném vào partition nào trong topic. Nhiệm vụ này rất quan trọng, giúp cho kafka có khả năng "scale" tốt.

![kafka-3](/images/kafka-3.png)

### 1.3. Consumer.

- Thông thường thì một hệ thống messaging sẽ có 2 loại :

    - Queue: Một message sẽ được xử lý bời một consumer.

    - Pub/Sub: Một message sẽ được xử lý bởi một vài consumer thích hợp, tuỳ theo topic.

- Ở kafka chúng ta có một khái niệm gọi là consumer group giúp chúng ta có thể làm được đồng thời cả 2 loại trên, rất thú vị. Việc subscribe một topic sẽ được thực hiện bởi consumer group. Mỗi một message sẽ được gửi cho `duy nhất` một consumer instance trong một consumer group. Việc này dấn đến :

    - Nếu nhiều instance consumer có cùng group: chúng ta sẽ có một hệ thống queue.

    - Nếu mỗi instance là một group, chúng ta sẽ có một hệ thống pub/sub.

### 1.4. Use cases.

- Sử dụng như một hệ thống message queue thay thế cho ActiveMQ hay RabbitMQ.

- Tracking hành động người dùng : các thông số như page view, search action của user sẽ được publish vào một topic và sẽ được xử lý sau.

- Log Aggregration: log sẽ được gửi từ nhiều server về một nơi thống nhất, sau đó có thể được làm sạch và xử lý theo một logic nào đó.

- Event-Sourcing: Lưu lại trạng thái của hệ thống để có thể tái hiện trong trường hợp system bị down. 



## Install Kafka Centos 7

 - Dowload kafka
 
wget http://mirror.downloadvn.com/apache/kafka/1.1.0/kafka_2.11-1.1.0.tgz

 - Giải nén kafka
 
tar -zxvf kafka_2.11-1.1.0.tgz

##Install java8
yum install java-1.8.0-openjdk -y

#Echo enviroment

echo "192.168.20.30elk" >> /etc/hosts
echo "192.168.20.31 kafka" >> /etc/hosts
echo "export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk" >> /etc/environment
echo "export JRE_HOME=/usr/lib/jvm/jre" >> /etc/environment

#Firewall
firewall-cmd --add-port=9092/tcp
firewall-cmd --add-port=9092/tcp --permanent

##Config file :

config/server.properties
listeners=PLAINTEXT://kafka:9092

## Chạy file run
screen -d -m bin/zookeeper-server-start.sh config/zookeeper.properties
screen -d -m bin/kafka-server-start.sh config/server.properties

## Kiểm tra trạng thái cluster
ps aux | grep zookeeper.properties
ps aux | grep server.properties

## List topic
bin/kafka-topics.sh --list --zookeeper localhost:2181

## Theo dõi message có trong topic
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic test



===================================================


Cài đặt ELK centos 7

# Install java 8
Cai dat java 8
yum install java-1.8.0-openjdk -y

Kiểm tra version :
java -version

## Cài đặt Elasticsearch
  - Thêm repo
rpm --import http://packages.elastic.co/GPG-KEY-elasticsearch

 - Thêm file repo
cat <<EOF > /etc/yum.repos.d/elasticsearch.repo
[elasticsearch-6.x]
name=Elasticsearch repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF

 - Cài đặt elastic
yum install elasticsearch -y

 - Start và enable service
systemctl daemon-reload
systemctl enable elasticsearch
systemctl start elasticsearch

 - Thêm rule firewall
firewall-cmd --add-port=9200/tcp
firewall-cmd --add-port=9200/tcp --permanent

 - Kiểm tra dịch vụ Elasticsearch
curl -X GET http://localhost:9200
ieeeeeeeeeeeeee
## Cài đặt Logstash
 - Thêm file repo :
cat << EOF > /etc/yum.repos.d/logstash.repo
[logstash-6.x]
name=Elastic repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF

 - Cài đặt Logstash
yum install logstash -y

## Có thể không cấu hình phần này
 - Thêm SSL certificate dựa vào IP của ELK :
vi /etc/pki/tls/openssl.cnf
[ v3_ca ]
subjectAltName = IP: 192.168.100.36

 - Tạo self-singed certificate cho 365 :
cd /etc/pki/tls
openssl req -config /etc/pki/tls/openssl.cnf -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt



## Cấu hình Logstash input, output và filter file : 
cat << EOF > /etc/logstash/conf.d/02-logstash.conf
input {
     kafka {
            bootstrap_servers => '192.168.30.31:9092'
            topics => ["openstack"]
            codec => json {}
          }
}
filter {
     if "openstack" in [tags] {
      }
        grok {
         match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{DATA:pid} %{LOGLEVEL:log_level} %{GREEDYDATA:content}" }
        }

}
output {
     elasticsearch {
       hosts => ["localhost:9200"]
       sniffing => true
       index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
     }
}
EOF


 - Start và enable service
systemctl daemon-reload
systemctl start logstash
systemctl enable logstash

 - Cấu hình firewall cho phép Logstash nhận log từ client (port 5044)
firewall-cmd --add-port=5044/tcp
firewall-cmd --add-port=5044/tcp --permanent

## Cài đặt Kibana
 - Tạo repo cài đặt Kibana :
 
cat <<EOF > /etc/yum.repos.d/kibana.repo
[kibana-6.x]
name=Kibana repository for 6.x packages
baseurl=https://artifacts.elastic.co/packages/6.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
EOF

 - Cài đặt Kibana :
yum install kibana -y
sed -i 's/#server.host: "localhost"/server.host: "0.0.0.0"/'g /etc/kibana/kibana.yml

 - Start và enable Kibana 
systemctl daemon-reload
systemctl start kibana
systemctl enable kibana

 - Cho phép truy cập Kibana web interface (port 5601)
firewall-cmd --add-port=5601/tcp
firewall-cmd --add-port=5601/tcp --permanent
 
 - Đổi port mặc định 5601 -> 80
iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 5601

 - Chạy Kibana : http://192.168.0.29
 
## Cài đặt Nginx để làm proxy cho Kibana

yum install epel-release -y
yum install nginx httpd-tools -y
systemctl start nginx
systemctl enable nginx

## Cấu hình nginx 

cd /etc/nginx/
vi nginx.conf

Loại bổ nội dung phía trong phần : server {}

 - Tạo file cấu hình vi /etc/nginx/conf.d/kibana.conf
 
cat << EOF > /etc/nginx/conf.d/kibana.conf
server {
    listen 80;
 
    server_name elk-stack.co;
 
    auth_basic "Restricted Access";
    auth_basic_user_file /etc/nginx/.kibana-user;
 
    location / {
        proxy_pass http://localhost:5601;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
EOF

 - Tạo password cho user 
 
htpasswd -c /etc/nginx/.kibana-user admin

 - Restart service
 
systemctl start nginx


## Cài đặt Filebeat trên Client servers

## Cấu hình SSL, có thể bỏ qua
 - Copy SSL certificate từ server tới client :
scp /etc/pki/tls/certs/logstash-forwarder.crt root@192.168.0.100:/etc/pki/tls/certs/

 - import Elasticsearch pub GPG key tới rpm package manager : 
 
rpm --import http://packages.elastic.co/GPG-KEY-elasticsearch
 
## Cài đặt filebeat 
 - Tạo repo cho filebeat 
 
cat << EOF > /etc/yum.repos.d/filebeat.repo
[filebeat]
name=Filebeat for ELK clients
baseurl=https://packages.elastic.co/beats/yum/el/$basearch
enabled=1
gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearch
gpgcheck=1
EOF 


## Tải gói filebeat
 - Uubntu
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-amd64.deb
dpkg -i filebeat-6.2.3-amd64.deb

 - Centos
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.4-x86_64.rpm
rpm -vi filebeat-6.2.4-x86_64.rpm



## Cấu hình filebeat : /etc/filebeat/filebeat.yml

mv /etc/filebeat/filebeat.yml /etc/filebeat/filebeat.yml.orig
touch /etc/filebeat/filebeat.yml
cat << EOF > /etc/filebeat/filebeat.yml
filebeat.prospectors:
- type: log
  paths:
    - /var/log/cinder/*.log
  fields:{log_type: cinder}
- type: log
  paths:
    - /var/log/glance/*.log
  fields:{log_type: glance}
- type: log
  paths:
    - /var/log/keystone/*.log
  fields:{log_type: keystone}
- type: log
  paths:
    - /var/log/neutron/*.log
  fields:{log_type: neutron}
- type: log
  paths:
    - /var/log/nova/*.log
  fields:{log_type: nova}
- type: log
  paths:
    - /var/log/rabbitmq/*.log
  fields:{log_type: rabbitmq}
  multiline.pattern: ^\d
  multiline.negate: true
  multiline.match: after
- type: log
  paths:
    - /var/log/httpd/*.log
  fields:{log_type: http}
- type: log
  paths:
    - /var/log/messages
  fields:{log_type: syslog_cent}
tags:
- openstack
output.kafka:
 hosts: ["192.168.20.31:9092"]
 topic: openstack
EOF

 - Thêm hostname

echo "192.168.20.31 kafka" >> /etc/hosts

 - Start và enable Filebeat Centos
systemctl restart filebeat
systemctl enable filebeat

 - Start và enable Filebeat Ubuntu
service filebeat restart 
update-rc.d filebeat defaults
 - Kiểm tra filebeat
curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'